import { checkAudioQuality, getAudioQualitySuggestions, isSuitableForSpeechRecognition, preprocessAudio } from '@/utils/audioQualityChecker';
import { diagnoseBaiduSpeechIssues } from '@/utils/baiduSpeechApi';
import { checkSpeechRecognitionPermission, convertSpeechToText, diagnoseSpeechRecognition, getSpeechRecognitionConfigInfo, getSpeechRecognitionStatus } from '@/utils/speechToText';
import { Ionicons } from '@expo/vector-icons';
import { Audio } from 'expo-av';
import React, { useEffect, useMemo, useState } from 'react';
import { Alert, Animated, Platform, Pressable, StyleSheet, TouchableOpacity } from 'react-native';
import { ThemedText } from './ThemedText';

interface VoiceInputProps {
  onVoiceResult: (text: string) => void;
  disabled?: boolean;
}

export default function VoiceInput({ onVoiceResult, disabled = false }: VoiceInputProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [hasPermission, setHasPermission] = useState<boolean | null>(null);
  const [speechStatus, setSpeechStatus] = useState<{
    baiduAvailable: boolean;
    fallbackAvailable: boolean;
    primaryService: string;
  } | null>(null);
  const [configInfo, setConfigInfo] = useState<any>(null);
  const [diagnosis, setDiagnosis] = useState<any>(null);
  const [lastRecordingUri, setLastRecordingUri] = useState<string | null>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [sound, setSound] = useState<Audio.Sound | null>(null);
  const [baiduDiagnosis, setBaiduDiagnosis] = useState<any>(null);
  const pulseAnim = useMemo(() => new Animated.Value(1), []);

  useEffect(() => {
    // æ£€æŸ¥å½•éŸ³æƒé™
    (async () => {
      try {
        const permission = await checkSpeechRecognitionPermission();
        setHasPermission(permission);
        
        if (!permission) {
          console.log('âš ï¸ å½•éŸ³æƒé™æœªæˆäºˆ');
          setError('éœ€è¦å½•éŸ³æƒé™ï¼Œè¯·åœ¨è®¾ç½®ä¸­å…è®¸ä½¿ç”¨éº¦å…‹é£');
        } else {
          console.log('âœ… å½•éŸ³æƒé™å·²æˆäºˆ');
          setError(null);
        }
      } catch (error) {
        console.error('âŒ æƒé™æ£€æŸ¥å¤±è´¥:', error);
        setHasPermission(false);
        setError('æƒé™æ£€æŸ¥å¤±è´¥');
      }
    })();

    // æ£€æŸ¥è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€
    (async () => {
      try {
        const status = await getSpeechRecognitionStatus();
        setSpeechStatus(status);
        console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€:', status);
      } catch (error) {
        console.error('âŒ è·å–è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€å¤±è´¥:', error);
      }
    })();

    // è·å–é…ç½®ä¿¡æ¯
    try {
      const config = getSpeechRecognitionConfigInfo();
      setConfigInfo(config);
      console.log('ğŸ”§ è¯­éŸ³è¯†åˆ«é…ç½®ä¿¡æ¯:', config);
    } catch (error) {
      console.error('âŒ è·å–é…ç½®ä¿¡æ¯å¤±è´¥:', error);
    }
  }, []);

  useEffect(() => {
    if (isRecording) {
      Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, {
            toValue: 1.2,
            duration: 1000,
            useNativeDriver: true,
          }),
          Animated.timing(pulseAnim, {
            toValue: 1,
            duration: 1000,
            useNativeDriver: true,
          }),
        ])
      ).start();
    } else {
      pulseAnim.setValue(1);
    }
  }, [isRecording, pulseAnim]);

  // æ’­æ”¾å½•éŸ³
  const playRecording = async () => {
    if (!lastRecordingUri) {
      Alert.alert('æ²¡æœ‰å½•éŸ³', 'è¯·å…ˆå½•åˆ¶ä¸€æ®µéŸ³é¢‘');
      return;
    }

    try {
      setIsPlaying(true);
      
      // åœæ­¢å½“å‰æ’­æ”¾
      if (sound) {
        await sound.unloadAsync();
      }

      // åˆ›å»ºæ–°çš„éŸ³é¢‘æ’­æ”¾å™¨
      const { sound: newSound } = await Audio.Sound.createAsync(
        { uri: lastRecordingUri },
        { shouldPlay: true }
      );

      setSound(newSound);

      // ç›‘å¬æ’­æ”¾å®Œæˆ
      newSound.setOnPlaybackStatusUpdate((status) => {
        if (status.isLoaded && status.didJustFinish) {
          setIsPlaying(false);
        }
      });

      console.log('ğŸ”Š å¼€å§‹æ’­æ”¾å½•éŸ³:', lastRecordingUri);
    } catch (error) {
      console.error('âŒ æ’­æ”¾å½•éŸ³å¤±è´¥:', error);
      setIsPlaying(false);
      Alert.alert('æ’­æ”¾å¤±è´¥', 'æ— æ³•æ’­æ”¾å½•éŸ³æ–‡ä»¶');
    }
  };

  // åœæ­¢æ’­æ”¾
  const stopPlaying = async () => {
    if (sound) {
      try {
        await sound.stopAsync();
        await sound.unloadAsync();
        setSound(null);
        setIsPlaying(false);
        console.log('â¹ï¸ åœæ­¢æ’­æ”¾å½•éŸ³');
      } catch (error) {
        console.error('âŒ åœæ­¢æ’­æ”¾å¤±è´¥:', error);
      }
    }
  };

  // è¯Šæ–­ç™¾åº¦è¯­éŸ³API
  const diagnoseBaiduAPI = async () => {
    try {
      console.log('ğŸ” å¼€å§‹è¯Šæ–­ç™¾åº¦è¯­éŸ³API...');
      const diagnosis = await diagnoseBaiduSpeechIssues();
      setBaiduDiagnosis(diagnosis);
      
      // æ˜¾ç¤ºè¯Šæ–­ç»“æœ
      const message = diagnosis.recommendations.join('\n');
      Alert.alert('ç™¾åº¦è¯­éŸ³APIè¯Šæ–­ç»“æœ', message);
      
      console.log('ğŸ“‹ ç™¾åº¦è¯­éŸ³APIè¯Šæ–­ç»“æœ:', diagnosis);
    } catch (error) {
      console.error('âŒ è¯Šæ–­å¤±è´¥:', error);
      Alert.alert('è¯Šæ–­å¤±è´¥', error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯');
    }
  };

  const startRecording = async () => {
    if (disabled) return;

    // æ£€æŸ¥æƒé™
    if (!hasPermission) {
      Alert.alert(
        'éœ€è¦å½•éŸ³æƒé™',
        'è¯·åœ¨è®¾ç½®ä¸­å…è®¸åº”ç”¨ä½¿ç”¨éº¦å…‹é£ï¼Œç„¶åé‡è¯•',
        [
          { text: 'å–æ¶ˆ', style: 'cancel' },
          { text: 'å»è®¾ç½®', onPress: () => {
            // åœ¨iOSä¸Šå¯ä»¥æ‰“å¼€è®¾ç½®
            if (Platform.OS === 'ios') {
              // è¿™é‡Œå¯ä»¥æ·»åŠ æ‰“å¼€è®¾ç½®çš„é€»è¾‘
            }
          }}
        ]
      );
      return;
    }

    try {
      setError(null);
      setDiagnosis(null);
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      // ä½¿ç”¨ä¼˜åŒ–çš„å½•éŸ³è®¾ç½®ï¼Œç¡®ä¿é«˜è´¨é‡éŸ³é¢‘
      const { recording } = await Audio.Recording.createAsync({
        android: {
          extension: '.wav',
          outputFormat: 1, // PCM_16BIT
          audioEncoder: 1, // PCM_16BIT
          sampleRate: 16000, // åŒ¹é…ç™¾åº¦APIè¦æ±‚
          numberOfChannels: 1, // å•å£°é“
          bitRate: 256000, // é«˜è´¨é‡æ¯”ç‰¹ç‡
        },
        ios: {
          extension: '.wav',
          outputFormat: 1, // LINEARPCM
          audioQuality: 2, // MAX - æœ€é«˜è´¨é‡
          sampleRate: 16000, // åŒ¹é…ç™¾åº¦APIè¦æ±‚
          numberOfChannels: 1, // å•å£°é“
          bitRate: 256000, // é«˜è´¨é‡æ¯”ç‰¹ç‡
          linearPCMBitDepth: 16, // 16ä½æ·±åº¦
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
        web: {
          mimeType: 'audio/wav',
        },
      });
      
      setRecording(recording);
      setIsRecording(true);
      console.log('ğŸ¤ å¼€å§‹å½•éŸ³...');
    } catch (err) {
      console.error('âŒ å½•éŸ³å¤±è´¥:', err);
      setError('å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•');
      Alert.alert('å½•éŸ³å¤±è´¥', 'æ— æ³•å¼€å§‹å½•éŸ³ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™');
    }
  };

  const stopRecording = async () => {
    if (!recording) return;

    setIsRecording(false);
    setIsProcessing(true);
    
    try {
      console.log('ğŸ›‘ åœæ­¢å½•éŸ³...');
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      setRecording(null);

      if (uri) {
        console.log('ğŸ“ å½•éŸ³æ–‡ä»¶URI:', uri);
        setLastRecordingUri(uri); // ä¿å­˜å½•éŸ³æ–‡ä»¶URI
        
        try {
          // é¢„å¤„ç†éŸ³é¢‘æ–‡ä»¶
          const processedUri = await preprocessAudio(uri);
          console.log('âœ… éŸ³é¢‘é¢„å¤„ç†å®Œæˆ');
          
          // æ£€æŸ¥éŸ³é¢‘è´¨é‡
          const audioQuality = await checkAudioQuality(processedUri);
          console.log('ğŸµ éŸ³é¢‘è´¨é‡æ£€æŸ¥:', audioQuality);
          
          if (!isSuitableForSpeechRecognition(audioQuality)) {
            const suggestions = getAudioQualitySuggestions(audioQuality);
            console.log('âš ï¸ éŸ³é¢‘è´¨é‡å»ºè®®:', suggestions);
            setError(suggestions[0] || 'éŸ³é¢‘è´¨é‡ä¸é€‚åˆè¯†åˆ«ï¼Œè¯·é‡æ–°å½•éŸ³');
            return;
          }
          
          // è¿›è¡Œè¯Šæ–­
          const diagnosisResult = await diagnoseSpeechRecognition(processedUri);
          setDiagnosis(diagnosisResult);
          console.log('ğŸ” è¯Šæ–­ç»“æœ:', diagnosisResult);
          
          // è°ƒç”¨è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½
          console.log('ğŸ”„ å¼€å§‹è¯­éŸ³è¯†åˆ«...');
          const recognizedText = await convertSpeechToText(processedUri);
          
          if (recognizedText) {
            console.log('âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ:', recognizedText);
            onVoiceResult(recognizedText);
            setError(null);
          } else {
            console.log('âŒ è¯­éŸ³è¯†åˆ«ç»“æœä¸ºç©º');
            setError('æ— æ³•è¯†åˆ«è¯­éŸ³å†…å®¹ï¼Œè¯·é‡æ–°å½•éŸ³');
          }
        } catch (error) {
          console.error('âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
          setError(error instanceof Error ? error.message : 'è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
        }
      } else {
        console.log('âŒ å½•éŸ³æ–‡ä»¶URIä¸ºç©º');
        setError('å½•éŸ³æ–‡ä»¶ç”Ÿæˆå¤±è´¥');
      }
    } catch (error) {
      console.error('âŒ åœæ­¢å½•éŸ³å¤±è´¥:', error);
      setError('å½•éŸ³å¤„ç†å¤±è´¥');
    } finally {
      setIsProcessing(false);
    }
  };

  const handlePressIn = () => {
    if (!disabled && !isProcessing && hasPermission) {
      startRecording();
    }
  };

  const handlePressOut = () => {
    if (isRecording) {
      stopRecording();
    }
  };

  const getButtonText = () => {
    if (!hasPermission) return 'éœ€è¦æƒé™';
    if (isProcessing) return 'è¯†åˆ«ä¸­...';
    if (isRecording) return 'æ¾å¼€ç»“æŸ';
    return 'æŒ‰ä½è¯´è¯';
  };

  const getButtonColor = () => {
    if (!hasPermission) return '#999';
    if (isProcessing) return '#FF9500';
    if (isRecording) return '#FF3B30';
    return '#007AFF';
  };

  const getIconName = () => {
    if (!hasPermission) return 'mic-off';
    if (isProcessing) return 'hourglass';
    if (isRecording) return 'stop';
    return 'mic';
  };

  const getStatusText = () => {
    if (!hasPermission) return 'éº¦å…‹é£æƒé™è¢«æ‹’ç»';
    if (!speechStatus) return 'æ£€æŸ¥æœåŠ¡çŠ¶æ€...';
    
    if (speechStatus.baiduAvailable) {
      return 'ä½¿ç”¨ç™¾åº¦è¯­éŸ³API';
    } else if (speechStatus.fallbackAvailable) {
      return 'ä½¿ç”¨æ¨¡æ‹Ÿè¯†åˆ«';
    } else {
      return 'è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨';
    }
  };

  const getConfigStatusText = () => {
    if (!configInfo) return '';
    
    if (configInfo.isConfigured) {
      return 'ç™¾åº¦APIå·²é…ç½®';
    } else {
      return 'ç™¾åº¦APIæœªé…ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè¯†åˆ«';
    }
  };

  const getDiagnosisText = () => {
    if (!diagnosis) return '';
    
    const issues = [];
    if (diagnosis.audioRecording.issues.length > 0) {
      issues.push(`å½•éŸ³: ${diagnosis.audioRecording.issues[0]}`);
    }
    if (diagnosis.apiStatus.issues.length > 0) {
      issues.push(`API: ${diagnosis.apiStatus.issues[0]}`);
    }
    
    return issues.length > 0 ? issues.join(' | ') : 'è¯Šæ–­æ­£å¸¸';
  };

  return (
    <Pressable
      style={[styles.container, disabled && styles.disabled]}
      onPressIn={handlePressIn}
      onPressOut={handlePressOut}
      disabled={disabled || isProcessing || !hasPermission}
    >
      <Animated.View
        style={[
          styles.button,
          { backgroundColor: getButtonColor() },
          { transform: [{ scale: pulseAnim }] },
        ]}
      >
        <Ionicons
          name={getIconName() as any}
          size={32}
          color="#FFFFFF"
        />
      </Animated.View>
      <ThemedText style={styles.buttonText}>{getButtonText()}</ThemedText>
      {speechStatus && (
        <ThemedText style={styles.statusText}>{getStatusText()}</ThemedText>
      )}
      {configInfo && (
        <ThemedText style={styles.configText}>{getConfigStatusText()}</ThemedText>
      )}
      {diagnosis && (
        <ThemedText style={styles.diagnosisText}>{getDiagnosisText()}</ThemedText>
      )}
      {error && (
        <ThemedText style={styles.errorText}>{error}</ThemedText>
      )}
      
      {/* æ’­æ”¾æµ‹è¯•æŒ‰é’® */}
      {lastRecordingUri && (
        <TouchableOpacity
          style={[styles.playButton, isPlaying && styles.playButtonActive]}
          onPress={isPlaying ? stopPlaying : playRecording}
          disabled={isProcessing}
        >
          <Ionicons
            name={isPlaying ? "stop" : "play"}
            size={20}
            color="#FFFFFF"
          />
          <ThemedText style={styles.playButtonText}>
            {isPlaying ? 'åœæ­¢æ’­æ”¾' : 'æ’­æ”¾å½•éŸ³'}
          </ThemedText>
        </TouchableOpacity>
      )}
      
      {/* è¯Šæ–­æŒ‰é’® */}
      <TouchableOpacity
        style={styles.diagnoseButton}
        onPress={diagnoseBaiduAPI}
        disabled={isProcessing}
      >
        <Ionicons
          name="bug"
          size={16}
          color="#FFFFFF"
        />
        <ThemedText style={styles.diagnoseButtonText}>
          è¯Šæ–­ç™¾åº¦API
        </ThemedText>
      </TouchableOpacity>
    </Pressable>
  );
}

const styles = StyleSheet.create({
  container: {
    justifyContent: 'center',
    alignItems: 'center',
    paddingVertical: 12, // å‡å°‘å‚ç›´é—´è·ï¼Œä»20æ”¹ä¸º12
    paddingBottom: Platform.OS === 'android' ? 0 : 12, // å‡å°‘Androidåº•éƒ¨é—´è·ï¼Œä»20æ”¹ä¸º12
    zIndex: 1,
  },
  button: {
    width: 80,
    height: 80,
    borderRadius: 40,
    justifyContent: 'center',
    alignItems: 'center',
  },
  disabled: {
    opacity: 0.5,
  },
  buttonText: {
    fontSize: 16,
    color: '#666',
    textAlign: 'center',
    marginTop: 8, // å‡å°‘é¡¶éƒ¨é—´è·ï¼Œä»12æ”¹ä¸º8
  },
  statusText: {
    fontSize: 12,
    color: '#999',
    textAlign: 'center',
    marginTop: 4,
  },
  errorText: {
    fontSize: 14,
    color: '#FF3B30',
    textAlign: 'center',
    marginTop: 6, // å‡å°‘é¡¶éƒ¨é—´è·ï¼Œä»8æ”¹ä¸º6
  },
  configText: {
    fontSize: 12,
    color: '#999',
    textAlign: 'center',
    marginTop: 2,
  },
  diagnosisText: {
    fontSize: 12,
    color: '#FF9500',
    textAlign: 'center',
    marginTop: 2,
  },
  playButton: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    backgroundColor: '#007AFF',
    paddingVertical: 10,
    paddingHorizontal: 20,
    borderRadius: 20,
    marginTop: 10,
    width: '80%', // è°ƒæ•´å®½åº¦
    alignSelf: 'center',
  },
  playButtonActive: {
    backgroundColor: '#FF3B30',
  },
  playButtonText: {
    color: '#FFFFFF',
    marginLeft: 5,
    fontSize: 14,
  },
  diagnoseButton: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    backgroundColor: '#FF3B30',
    paddingVertical: 10,
    paddingHorizontal: 20,
    borderRadius: 20,
    marginTop: 10,
    width: '80%', // è°ƒæ•´å®½åº¦
    alignSelf: 'center',
  },
  diagnoseButtonText: {
    color: '#FFFFFF',
    marginLeft: 5,
    fontSize: 14,
  },
}); 