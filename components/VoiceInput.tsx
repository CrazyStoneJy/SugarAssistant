import { checkAudioQuality, getAudioQualitySuggestions, isSuitableForSpeechRecognition } from '@/utils/audioQualityChecker';
import { checkSpeechRecognitionPermission, convertSpeechToText, getSpeechRecognitionStatus } from '@/utils/speechToText';
import { Ionicons } from '@expo/vector-icons';
import { Audio } from 'expo-av';
import React, { useEffect, useMemo, useState } from 'react';
import { Alert, Animated, Platform, Pressable, StyleSheet } from 'react-native';
import { ThemedText } from './ThemedText';

interface VoiceInputProps {
  onVoiceResult: (text: string) => void;
  disabled?: boolean;
}

export default function VoiceInput({ onVoiceResult, disabled = false }: VoiceInputProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [speechStatus, setSpeechStatus] = useState<{
    baiduAvailable: boolean;
    fallbackAvailable: boolean;
    primaryService: string;
  } | null>(null);
  const pulseAnim = useMemo(() => new Animated.Value(1), []);

  useEffect(() => {
    // è¯·æ±‚å½•éŸ³æƒé™
    (async () => {
      const hasPermission = await checkSpeechRecognitionPermission();
      if (!hasPermission) {
        Alert.alert('éœ€è¦å½•éŸ³æƒé™', 'è¯·åœ¨è®¾ç½®ä¸­å…è®¸åº”ç”¨ä½¿ç”¨éº¦å…‹é£');
      }
    })();

    // æ£€æŸ¥è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€
    (async () => {
      try {
        const status = await getSpeechRecognitionStatus();
        setSpeechStatus(status);
        console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€:', status);
      } catch (error) {
        console.error('è·å–è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€å¤±è´¥:', error);
      }
    })();
  }, []);

  useEffect(() => {
    if (isRecording) {
      Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, {
            toValue: 1.2,
            duration: 1000,
            useNativeDriver: true,
          }),
          Animated.timing(pulseAnim, {
            toValue: 1,
            duration: 1000,
            useNativeDriver: true,
          }),
        ])
      ).start();
    } else {
      pulseAnim.setValue(1);
    }
  }, [isRecording, pulseAnim]);

  const startRecording = async () => {
    if (disabled) return;

    try {
      setError(null);
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
      });

      // ä½¿ç”¨æ›´é€‚åˆè¯­éŸ³è¯†åˆ«çš„å½•éŸ³è®¾ç½®
      const { recording } = await Audio.Recording.createAsync({
        android: {
          extension: '.wav',
          outputFormat: 1, // PCM_16BIT
          audioEncoder: 1, // PCM_16BIT
          sampleRate: 16000,
          numberOfChannels: 1,
          bitRate: 256000,
        },
        ios: {
          extension: '.wav',
          outputFormat: 1, // LINEARPCM
          audioQuality: 1, // HIGH
          sampleRate: 16000,
          numberOfChannels: 1,
          bitRate: 256000,
          linearPCMBitDepth: 16,
          linearPCMIsBigEndian: false,
          linearPCMIsFloat: false,
        },
        web: {
          mimeType: 'audio/wav',
        },
      });
      setRecording(recording);
      setIsRecording(true);
    } catch (err) {
      console.error('å½•éŸ³å¤±è´¥', err);
      setError('å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•');
      Alert.alert('å½•éŸ³å¤±è´¥', 'æ— æ³•å¼€å§‹å½•éŸ³');
    }
  };

  const stopRecording = async () => {
    if (!recording) return;

    setIsRecording(false);
    setIsProcessing(true);
    
    try {
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      setRecording(null);

      if (uri) {
        // æ£€æŸ¥éŸ³é¢‘è´¨é‡
        try {
          const audioQuality = await checkAudioQuality(uri);
          console.log('ğŸµ éŸ³é¢‘è´¨é‡æ£€æŸ¥:', audioQuality);
          
          if (!isSuitableForSpeechRecognition(audioQuality)) {
            const suggestions = getAudioQualitySuggestions(audioQuality);
            console.log('âš ï¸ éŸ³é¢‘è´¨é‡å»ºè®®:', suggestions);
            setError(suggestions[0] || 'éŸ³é¢‘è´¨é‡ä¸é€‚åˆè¯†åˆ«');
            return;
          }
          
          // è°ƒç”¨è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½
          const recognizedText = await convertSpeechToText(uri);
          if (recognizedText) {
            onVoiceResult(recognizedText);
          } else {
            setError('æ— æ³•è¯†åˆ«è¯­éŸ³å†…å®¹');
          }
        } catch (error) {
          console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
          setError('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
        }
      }
    } catch (error) {
      console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error);
      setError('å½•éŸ³å¤„ç†å¤±è´¥');
    } finally {
      setIsProcessing(false);
    }
  };

  const handlePressIn = () => {
    if (!disabled && !isProcessing) {
      startRecording();
    }
  };

  const handlePressOut = () => {
    if (isRecording) {
      stopRecording();
    }
  };

  const getButtonText = () => {
    if (isProcessing) return 'è¯†åˆ«ä¸­...';
    if (isRecording) return 'æ¾å¼€ç»“æŸ';
    return 'æŒ‰ä½è¯´è¯';
  };

  const getButtonColor = () => {
    if (isProcessing) return '#FF9500';
    if (isRecording) return '#FF3B30';
    return '#007AFF';
  };

  const getIconName = () => {
    if (isProcessing) return 'hourglass';
    if (isRecording) return 'stop';
    return 'mic';
  };

  const getStatusText = () => {
    if (!speechStatus) return '';
    
    if (speechStatus.baiduAvailable) {
      return 'ä½¿ç”¨ç™¾åº¦è¯­éŸ³API';
    } else if (speechStatus.fallbackAvailable) {
      return 'ä½¿ç”¨æ¨¡æ‹Ÿè¯†åˆ«';
    } else {
      return 'è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨';
    }
  };

  return (
    <Pressable
      style={[styles.container, disabled && styles.disabled]}
      onPressIn={handlePressIn}
      onPressOut={handlePressOut}
      disabled={disabled || isProcessing}
    >
      <Animated.View
        style={[
          styles.button,
          { backgroundColor: getButtonColor() },
          { transform: [{ scale: pulseAnim }] },
        ]}
      >
        <Ionicons
          name={getIconName() as any}
          size={32}
          color="#FFFFFF"
        />
      </Animated.View>
      <ThemedText style={styles.buttonText}>{getButtonText()}</ThemedText>
      {speechStatus && (
        <ThemedText style={styles.statusText}>{getStatusText()}</ThemedText>
      )}
      {error && (
        <ThemedText style={styles.errorText}>{error}</ThemedText>
      )}
    </Pressable>
  );
}

const styles = StyleSheet.create({
  container: {
    justifyContent: 'center',
    alignItems: 'center',
    paddingVertical: 20,
    paddingBottom: Platform.OS === 'android' ? 0 : 20,
    zIndex: 1,
  },
  button: {
    width: 80,
    height: 80,
    borderRadius: 40,
    justifyContent: 'center',
    alignItems: 'center',
  },
  disabled: {
    opacity: 0.5,
  },
  buttonText: {
    fontSize: 16,
    color: '#666',
    textAlign: 'center',
    marginTop: 12,
  },
  statusText: {
    fontSize: 12,
    color: '#999',
    textAlign: 'center',
    marginTop: 4,
  },
  errorText: {
    fontSize: 14,
    color: '#FF3B30',
    textAlign: 'center',
    marginTop: 8,
  },
}); 