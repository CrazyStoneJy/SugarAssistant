import { getBaiduSpeechConfig, isBaiduSpeechConfigured } from '@/config/env';
import { Audio } from 'expo-av';
import { checkBaiduSpeechAvailability, recognizeSpeechWithBaidu } from './baiduSpeechApi';

// è¯­éŸ³è¯†åˆ«ç»“æœ
export interface SpeechRecognitionResult {
  text: string;
  confidence: number;
  isFinal: boolean;
}

// è¯­éŸ³è¯†åˆ«çŠ¶æ€
export interface SpeechRecognitionState {
  isListening: boolean;
  isProcessing: boolean;
  error: string | null;
}

/**
 * è¯Šæ–­éŸ³é¢‘å½•åˆ¶å’Œè¯†åˆ«é—®é¢˜
 */
export async function diagnoseSpeechRecognition(audioUri: string): Promise<{
  audioRecording: {
    fileExists: boolean;
    fileSize: number;
    fileSizeKB: number;
    estimatedDuration: number;
    issues: string[];
  };
  apiStatus: {
    isConfigured: boolean;
    hasValidToken: boolean;
    networkAccessible: boolean;
    issues: string[];
  };
  recommendations: string[];
}> {
  const diagnosis = {
    audioRecording: {
      fileExists: false,
      fileSize: 0,
      fileSizeKB: 0,
      estimatedDuration: 0,
      issues: [] as string[],
    },
    apiStatus: {
      isConfigured: false,
      hasValidToken: false,
      networkAccessible: false,
      issues: [] as string[],
    },
    recommendations: [] as string[],
  };

  try {
    // 1. æ£€æŸ¥éŸ³é¢‘å½•åˆ¶
    console.log('ğŸ” å¼€å§‹éŸ³é¢‘å½•åˆ¶è¯Šæ–­...');
    const { getInfoAsync } = await import('expo-file-system');
    const fileInfo = await getInfoAsync(audioUri);
    
    diagnosis.audioRecording.fileExists = fileInfo.exists;
    const fileSize = fileInfo.exists && 'size' in fileInfo ? (fileInfo as any).size || 0 : 0;
    diagnosis.audioRecording.fileSize = fileSize;
    diagnosis.audioRecording.fileSizeKB = Math.round(fileSize / 1024);
    
    // æ›´å‡†ç¡®çš„å½•éŸ³æ—¶é•¿è®¡ç®— - é’ˆå¯¹PCMæ ¼å¼ä¼˜åŒ–
    // PCMæ ¼å¼æ–‡ä»¶å¤´è¾ƒå°ï¼Œé€šå¸¸åªæœ‰å‡ ä¸ªå­—èŠ‚çš„å…ƒæ•°æ®
    const headerSize = 50; // PCMæ ¼å¼æ–‡ä»¶å¤´è¾ƒå°ï¼Œé¢„ç•™50å­—èŠ‚
    const actualAudioSize = Math.max(fileSize - headerSize, 0);
    const bytesPerSecond = 16000 * 2 * 1; // é‡‡æ ·ç‡ * å­—èŠ‚æ•°/æ ·æœ¬ * å£°é“æ•°
    diagnosis.audioRecording.estimatedDuration = actualAudioSize / bytesPerSecond;
    
    console.log('ğŸ“Š PCMéŸ³é¢‘æ–‡ä»¶è¯¦ç»†åˆ†æ:', {
      fileSize,
      fileSizeKB: Math.round(fileSize / 1024),
      actualAudioSize,
      headerSize,
      bytesPerSecond,
      estimatedDuration: Math.round(diagnosis.audioRecording.estimatedDuration * 100) / 100,
      format: 'PCM',
    });
    
    if (!fileInfo.exists) {
      diagnosis.audioRecording.issues.push('éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨');
    } else if (fileSize < 1024) { // å°äº1KB - ç»Ÿä¸€æ ‡å‡†
      diagnosis.audioRecording.issues.push('éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½å½•éŸ³æ—¶é—´è¿‡çŸ­');
    } else if (fileSize > 100 * 1024 * 1024) {
      diagnosis.audioRecording.issues.push('éŸ³é¢‘æ–‡ä»¶å¤ªå¤§ï¼Œå¯èƒ½å½•éŸ³æ—¶é—´è¿‡é•¿');
    }
    
    if (diagnosis.audioRecording.estimatedDuration < 1) { // å°äº1ç§’ - ç»Ÿä¸€æ ‡å‡†
      diagnosis.audioRecording.issues.push(`å½•éŸ³æ—¶é—´è¿‡çŸ­ (${Math.round(diagnosis.audioRecording.estimatedDuration * 100) / 100}ç§’)ï¼Œå»ºè®®è‡³å°‘1ç§’`);
    } else if (diagnosis.audioRecording.estimatedDuration > 30) {
      diagnosis.audioRecording.issues.push(`å½•éŸ³æ—¶é—´è¿‡é•¿ (${Math.round(diagnosis.audioRecording.estimatedDuration * 100) / 100}ç§’)ï¼Œå»ºè®®ä¸è¶…è¿‡30ç§’`);
    }
    
    console.log('ğŸ“ éŸ³é¢‘å½•åˆ¶è¯Šæ–­ç»“æœ:', diagnosis.audioRecording);
    
    // 2. æ£€æŸ¥APIçŠ¶æ€
    console.log('ğŸ” å¼€å§‹APIçŠ¶æ€è¯Šæ–­...');
    diagnosis.apiStatus.isConfigured = isBaiduSpeechConfigured();
    
    if (diagnosis.apiStatus.isConfigured) {
      try {
        // å°è¯•è·å–tokenæ¥æ£€æŸ¥APIé…ç½®
        const { getBaiduToken } = await import('./baiduSpeechApi');
        await getBaiduToken();
        diagnosis.apiStatus.hasValidToken = true;
      } catch (error) {
        diagnosis.apiStatus.issues.push(`Tokenè·å–å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
      }
      
      // æ£€æŸ¥ç½‘ç»œè¿æ¥
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 5000);
        
        const response = await fetch('https://vop.baidu.com/pro_api', {
          method: 'HEAD',
          signal: controller.signal,
        });
        
        clearTimeout(timeoutId);
        diagnosis.apiStatus.networkAccessible = response.status !== 0;
      } catch (error) {
        diagnosis.apiStatus.issues.push('ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œæ— æ³•è®¿é—®ç™¾åº¦API');
      }
    } else {
      diagnosis.apiStatus.issues.push('ç™¾åº¦è¯­éŸ³APIæœªé…ç½®');
    }
    
    console.log('ğŸŒ APIçŠ¶æ€è¯Šæ–­ç»“æœ:', diagnosis.apiStatus);
    
    // 3. ç”Ÿæˆå»ºè®®
    if (diagnosis.audioRecording.issues.length > 0) {
      diagnosis.recommendations.push('ğŸ¤ éŸ³é¢‘å½•åˆ¶é—®é¢˜ï¼š');
      diagnosis.recommendations.push(...diagnosis.audioRecording.issues.map(issue => `  - ${issue}`));
    }
    
    if (diagnosis.apiStatus.issues.length > 0) {
      diagnosis.recommendations.push('ğŸŒ APIé…ç½®é—®é¢˜ï¼š');
      diagnosis.recommendations.push(...diagnosis.apiStatus.issues.map(issue => `  - ${issue}`));
    }
    
    if (diagnosis.recommendations.length === 0) {
      diagnosis.recommendations.push('âœ… éŸ³é¢‘å½•åˆ¶å’ŒAPIé…ç½®éƒ½æ­£å¸¸');
    }
    
    console.log('ğŸ’¡ è¯Šæ–­å»ºè®®:', diagnosis.recommendations);
    
  } catch (error) {
    console.error('âŒ è¯Šæ–­è¿‡ç¨‹å‡ºé”™:', error);
    diagnosis.recommendations.push(`âŒ è¯Šæ–­å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
  }
  
  return diagnosis;
}

/**
 * ä½¿ç”¨ç™¾åº¦è¯­éŸ³APIè¿›è¡Œè¯­éŸ³è½¬æ–‡æœ¬
 */
export async function convertSpeechToText(audioUri: string): Promise<string> {
  try {
    console.log('ğŸ¤ å¼€å§‹è¯­éŸ³è½¬æ–‡æœ¬å¤„ç†...');
    
    // é¦–å…ˆè¿›è¡Œè¯Šæ–­
    const diagnosis = await diagnoseSpeechRecognition(audioUri);
    console.log('ğŸ” è¯Šæ–­ç»“æœ:', diagnosis);
    
    // é¦–å…ˆæ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    const { getInfoAsync } = await import('expo-file-system');
    const fileInfo = await getInfoAsync(audioUri);
    
    if (!fileInfo.exists) {
      throw new Error('éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨');
    }
    
    console.log('ğŸ“ éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯:', {
      uri: audioUri,
      size: fileInfo.size,
      sizeKB: Math.round((fileInfo.size || 0) / 1024),
      estimatedDuration: Math.round((fileInfo.size || 0) / (16000 * 2 * 1) * 100) / 100,
    });
    
    // æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°
    if ((fileInfo.size || 0) < 1024) {
      throw new Error('éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½å½•éŸ³æ—¶é—´è¿‡çŸ­ï¼Œè¯·é‡æ–°å½•éŸ³');
    }
    
    if ((fileInfo.size || 0) > 100 * 1024 * 1024) {
      throw new Error('éŸ³é¢‘æ–‡ä»¶å¤ªå¤§ï¼Œè¯·ç¼©çŸ­å½•éŸ³æ—¶é—´');
    }
    
    // å°è¯•ä½¿ç”¨ç™¾åº¦è¯­éŸ³API
    const isBaiduAvailable = await checkBaiduSpeechAvailability();
    
    if (isBaiduAvailable) {
      console.log('âœ… ä½¿ç”¨ç™¾åº¦è¯­éŸ³APIè¿›è¡Œè¯†åˆ«');
      try {
        return await recognizeSpeechWithBaidu(audioUri);
      } catch (baiduError) {
        console.error('âŒ ç™¾åº¦è¯­éŸ³APIè¯†åˆ«å¤±è´¥:', baiduError);
        console.log('ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿè¯†åˆ«');
        return await convertSpeechToTextMock(audioUri);
      }
    } else {
      console.log('âš ï¸ ç™¾åº¦è¯­éŸ³APIä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿè¯†åˆ«');
      return await convertSpeechToTextMock(audioUri);
    }
  } catch (error) {
    console.error('âŒ è¯­éŸ³è½¬æ–‡æœ¬å¤±è´¥:', error);
    
    // å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
    if (error instanceof Error) {
      if (error.message.includes('éŸ³é¢‘æ–‡ä»¶å¤ªå°')) {
        throw new Error('å½•éŸ³æ—¶é—´å¤ªçŸ­ï¼Œè¯·æŒ‰ä½æŒ‰é’®è¯´è¯è‡³å°‘1ç§’');
      }
      if (error.message.includes('éŸ³é¢‘æ–‡ä»¶å¤ªå¤§')) {
        throw new Error('å½•éŸ³æ—¶é—´å¤ªé•¿ï¼Œè¯·ç¼©çŸ­åˆ°30ç§’ä»¥å†…');
      }
      if (error.message.includes('ç½‘ç»œ')) {
        throw new Error('ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•');
      }
      if (error.message.includes('æƒé™')) {
        throw new Error('éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨è®¾ç½®ä¸­å…è®¸ä½¿ç”¨éº¦å…‹é£');
      }
    }
    
    throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
  }
}

/**
 * æ¨¡æ‹Ÿè¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
 */
async function convertSpeechToTextMock(audioUri: string): Promise<string> {
  try {
    // æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
    await new Promise(resolve => setTimeout(resolve, 1500));
    
    // æ ¹æ®éŸ³é¢‘URIç”Ÿæˆä¸€ä¸ª"éšæœº"ç»“æœï¼Œç¡®ä¿ç›¸åŒå½•éŸ³å¾—åˆ°ç›¸åŒç»“æœ
    const hash = simpleHash(audioUri);
    const mockResults = [
      'ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ',
      'æˆ‘æƒ³é—®ä¸€ä¸ªé—®é¢˜',
      'è¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä¿¡æ¯',
      'è°¢è°¢ä½ çš„å¸®åŠ©',
      'è¿™ä¸ªåŠŸèƒ½å¾ˆå¥½ç”¨',
      'æˆ‘æƒ³äº†è§£ä¸€ä¸‹è¿™ä¸ªåº”ç”¨',
      'è¯·ç»™æˆ‘ä¸€äº›å»ºè®®',
      'ä»Šå¤©å¿ƒæƒ…ä¸é”™',
      'æˆ‘æƒ³å­¦ä¹ æ–°çŸ¥è¯†',
      'è¯·å¸®æˆ‘è®¾ç½®æé†’',
      'è¿™ä¸ªåº”ç”¨å¾ˆæ£’',
      'æˆ‘æƒ³äº†è§£æ›´å¤šåŠŸèƒ½',
      'è¯·å‘Šè¯‰æˆ‘ä½¿ç”¨æ–¹æ³•',
      'è°¢è°¢ä½ çš„è€å¿ƒ',
      'æˆ‘æƒ³æµ‹è¯•ä¸€ä¸‹è¯­éŸ³åŠŸèƒ½',
      'è¿™ä¸ªç•Œé¢å¾ˆå‹å¥½',
      'è¯·å¸®æˆ‘æŸ¥è¯¢è¡€ç³–ç›¸å…³ä¿¡æ¯',
      'æˆ‘æƒ³äº†è§£ç³–å°¿ç—…é¥®é£Ÿå»ºè®®',
      'è¯·å‘Šè¯‰æˆ‘å“ªäº›é£Ÿç‰©é€‚åˆç³–å°¿ç—…äºº',
      'æˆ‘æƒ³äº†è§£å‡ç³–æŒ‡æ•°çš„æ¦‚å¿µ',
      'è¯·æ¨èä¸€äº›ä½ç³–é£Ÿç‰©',
      'æˆ‘æƒ³äº†è§£å¦‚ä½•æ§åˆ¶è¡€ç³–',
      'è¯·å‘Šè¯‰æˆ‘ç³–å°¿ç—…çš„æ³¨æ„äº‹é¡¹',
      'æˆ‘æƒ³äº†è§£èƒ°å²›ç´ çš„ä½œç”¨',
      'è¯·æ¨èä¸€äº›å¥åº·çš„é¥®é£Ÿä¹ æƒ¯',
    ];
    
    // æ ¹æ®å“ˆå¸Œå€¼é€‰æ‹©ç»“æœï¼Œç¡®ä¿ç›¸åŒå½•éŸ³å¾—åˆ°ç›¸åŒç»“æœ
    const index = hash % mockResults.length;
    const result = mockResults[index];
    
    console.log('ğŸ­ æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ:', result);
    return result;
    
  } catch (error) {
    console.error('æ¨¡æ‹Ÿè¯­éŸ³è½¬æ–‡æœ¬å¤±è´¥:', error);
    throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
  }
}

// ç®€å•çš„å“ˆå¸Œå‡½æ•°ï¼Œç”¨äºç”Ÿæˆ"éšæœº"ç»“æœ
function simpleHash(str: string): number {
  let hash = 0;
  for (let i = 0; i < str.length; i++) {
    const char = str.charCodeAt(i);
    hash = ((hash << 5) - hash) + char;
    hash = hash & hash; // è½¬æ¢ä¸º32ä½æ•´æ•°
  }
  return Math.abs(hash);
}

/**
 * æ£€æŸ¥è¯­éŸ³è¯†åˆ«æƒé™
 */
export async function checkSpeechRecognitionPermission(): Promise<boolean> {
  try {
    const { status } = await Audio.requestPermissionsAsync();
    console.log('ğŸ¤ å½•éŸ³æƒé™çŠ¶æ€:', status);
    return status === 'granted';
  } catch (error) {
    console.error('âŒ æƒé™æ£€æŸ¥å¤±è´¥:', error);
    return false;
  }
}

/**
 * è·å–è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€
 */
export async function getSpeechRecognitionStatus() {
  try {
    const baiduStatus = await checkBaiduSpeechAvailability();
    
    const status = {
      baiduAvailable: baiduStatus,
      fallbackAvailable: true, // æ¨¡æ‹Ÿè¯†åˆ«æ€»æ˜¯å¯ç”¨
      primaryService: baiduStatus ? 'baidu' : 'mock',
    };
    
    console.log('ğŸ¤ è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€:', status);
    return status;
  } catch (error) {
    console.error('âŒ è·å–è¯­éŸ³è¯†åˆ«çŠ¶æ€å¤±è´¥:', error);
    return {
      baiduAvailable: false,
      fallbackAvailable: true,
      primaryService: 'mock',
    };
  }
}

/**
 * è·å–è¯¦ç»†çš„è¯­éŸ³è¯†åˆ«é…ç½®ä¿¡æ¯
 */
export function getSpeechRecognitionConfigInfo() {
  try {
    const config = getBaiduSpeechConfig();
    const isConfigured = isBaiduSpeechConfigured();
    
    return {
      isConfigured,
      hasAppId: !!config.appId && config.appId !== 'your_baidu_app_id_here',
      hasApiKey: !!config.apiKey && config.apiKey !== 'your_baidu_api_key_here',
      hasSecretKey: !!config.secretKey && config.secretKey !== 'your_baidu_secret_key_here',
      config: isConfigured ? {
        appId: config.appId.substring(0, 8) + '...',
        apiKey: config.apiKey.substring(0, 8) + '...',
        secretKey: config.secretKey.substring(0, 8) + '...',
      } : null,
    };
  } catch (error) {
    console.error('âŒ è·å–ç™¾åº¦è¯­éŸ³é…ç½®ä¿¡æ¯å¤±è´¥:', error);
    return {
      isConfigured: false,
      hasAppId: false,
      hasApiKey: false,
      hasSecretKey: false,
      config: null,
    };
  }
}
 